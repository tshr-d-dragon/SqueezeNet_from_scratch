{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emsZye9ZM0py",
        "outputId": "2693165e-169d-43ba-9145-d72e6766e1b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  3 09:17:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "2i9OtNd_M61A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "NxRbkqiZohGp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm"
      ],
      "metadata": {
        "id": "EpqzV4y0ohDp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, trainY, testX, testY = load_dataset()\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, testX)"
      ],
      "metadata": {
        "id": "ppkQSsU9ohA8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size = 0.15, random_state=42, shuffle=True, stratify=trainY)"
      ],
      "metadata": {
        "id": "QzFFL8JZI492"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQNet"
      ],
      "metadata": {
        "id": "VXWvsn9zNAA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout\n",
        "from keras.layers import Concatenate, Input, GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "def SqueezeNet(input_shape, classes):\n",
        "\n",
        "\n",
        "  def Fire(inputs, fs, fe):\n",
        "    \n",
        "    s1 = Conv2D(filters=fs, kernel_size=1, padding='same', use_bias=False, activation='relu')(inputs)\n",
        "    s1 = BatchNormalization()(s1)\n",
        "    e1 = Conv2D(filters=fe, kernel_size=1, padding='same', use_bias=False, activation='relu')(s1)\n",
        "    e1 = BatchNormalization()(e1)\n",
        "    e3 = Conv2D(filters=fe, kernel_size=3, padding='same', use_bias=False, activation='relu')(s1)\n",
        "    e3 = BatchNormalization()(e3)\n",
        "\n",
        "    output = Concatenate()([e1, e3])\n",
        "  \n",
        "    return output\n",
        "\n",
        "\n",
        "  inputs = Input(input_shape)\n",
        "  x1 = Conv2D(filters=96, kernel_size=7, strides=2, padding='same', use_bias=False, activation='relu')(inputs)\n",
        "  x1= s1 = BatchNormalization()(x1)\n",
        "  x1 = MaxPooling2D(pool_size=3, strides=2, padding='same')(x1)\n",
        "\n",
        "  f2 = Fire(x1, 16, 64)\n",
        "  f3 = Fire(f2, 16, 64)\n",
        "  f4 = Fire(f3, 32, 128)\n",
        "  x1 = MaxPooling2D(pool_size=3, strides=2, padding='same')(f4)\n",
        "\n",
        "  f5 = Fire(x1, 32, 128)\n",
        "  f6 = Fire(f5, 48, 192)\n",
        "  f7 = Fire(f6, 48, 192)\n",
        "  f8 = Fire(f7, 64, 256)\n",
        "  x1 = MaxPooling2D(pool_size=3, strides=2, padding='same')(f8)\n",
        "\n",
        "  f8 = Fire(x1, 64, 256)\n",
        "  x1 = Conv2D(filters=classes, kernel_size=1)(f8)\n",
        "  x1 = GlobalAveragePooling2D()(x1)\n",
        "\n",
        "  if classes == 1:\n",
        "    x1 = Activation('sigmoid')(x1)\n",
        "  else:\n",
        "    x1 = Activation('softmax')(x1)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=x1)\n",
        "  # model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "mdoel = SqueezeNet(input_shape=(224, 224, 3), classes=10)"
      ],
      "metadata": {
        "id": "14n5iyGbog-i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\"\"\" callbacks \"\"\"\n",
        "checkpoint_filepath = '/content/SQNET_{epoch}.h5'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    # monitor='val_iou_score',\n",
        "    # mode='max',\n",
        "    verbose = 1,\n",
        "    period = 5,\n",
        "    save_best_only=False\n",
        "    )\n",
        "\n",
        "callbacks = [\n",
        "    model_checkpoint_callback,\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.5, verbose=1),\n",
        "    CSVLogger('/content/SQNET.csv'),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=8)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTsedMyJog8E",
        "outputId": "a7304698-873b-4d9a-8aa7-2a57ab0eba6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SqueezeNet(input_shape = (32, 32, 3), classes=10)\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "NJfg6xhwog5d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = model.fit(\n",
        "    trainX, trainY,\n",
        "    validation_data=(valX, valY),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    steps_per_epoch=len(trainX)//128 + 1,\n",
        "    validation_steps=len(valX)//128 + 1,\n",
        "    callbacks=callbacks,\n",
        "    workers=1,\n",
        "    use_multiprocessing=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No4EKQq5og21",
        "outputId": "a7823199-4ad2-4320-823d-ddc5451bba7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "333/333 [==============================] - 29s 59ms/step - loss: 1.8030 - accuracy: 0.3450 - val_loss: 2.9986 - val_accuracy: 0.2045 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 1.4680 - accuracy: 0.4645 - val_loss: 2.2547 - val_accuracy: 0.2709 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "333/333 [==============================] - 16s 47ms/step - loss: 1.3673 - accuracy: 0.5028 - val_loss: 1.9375 - val_accuracy: 0.3676 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 1.1921 - accuracy: 0.5732 - val_loss: 1.2786 - val_accuracy: 0.5600 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 1.0741 - accuracy: 0.6169\n",
            "Epoch 5: val_loss improved from inf to 1.40558, saving model to /content/SQNET_5.h5\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 1.0741 - accuracy: 0.6168 - val_loss: 1.4056 - val_accuracy: 0.5284 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "333/333 [==============================] - 17s 50ms/step - loss: 0.9965 - accuracy: 0.6439 - val_loss: 1.6645 - val_accuracy: 0.4693 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.9538 - accuracy: 0.6628 - val_loss: 1.6555 - val_accuracy: 0.4839 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "333/333 [==============================] - 17s 52ms/step - loss: 1.0499 - accuracy: 0.6292 - val_loss: 1.5737 - val_accuracy: 0.5041 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.8520 - accuracy: 0.6998 - val_loss: 1.0843 - val_accuracy: 0.6412 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.7626 - accuracy: 0.7305\n",
            "Epoch 10: val_loss improved from 1.40558 to 1.37574, saving model to /content/SQNET_10.h5\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.7626 - accuracy: 0.7305 - val_loss: 1.3757 - val_accuracy: 0.5549 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.6799 - accuracy: 0.7600 - val_loss: 1.0559 - val_accuracy: 0.6529 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.6242 - accuracy: 0.7788 - val_loss: 1.3756 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.6364 - accuracy: 0.7744 - val_loss: 0.9979 - val_accuracy: 0.6767 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.5582 - accuracy: 0.8037 - val_loss: 1.2920 - val_accuracy: 0.6219 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.8324\n",
            "Epoch 15: val_loss improved from 1.37574 to 1.05868, saving model to /content/SQNET_15.h5\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.4758 - accuracy: 0.8324 - val_loss: 1.0587 - val_accuracy: 0.6799 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.4705 - accuracy: 0.8322 - val_loss: 1.2465 - val_accuracy: 0.6447 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.4003 - accuracy: 0.8566 - val_loss: 1.5434 - val_accuracy: 0.5727 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.5230 - accuracy: 0.8158\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.5230 - accuracy: 0.8157 - val_loss: 1.6281 - val_accuracy: 0.5684 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.2654 - accuracy: 0.9080 - val_loss: 1.2661 - val_accuracy: 0.6837 - lr: 5.0000e-04\n",
            "Epoch 20/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9297\n",
            "Epoch 20: val_loss did not improve from 1.05868\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.2032 - accuracy: 0.9296 - val_loss: 1.2835 - val_accuracy: 0.6973 - lr: 5.0000e-04\n",
            "Epoch 21/100\n",
            "333/333 [==============================] - 17s 50ms/step - loss: 0.1455 - accuracy: 0.9484 - val_loss: 1.6161 - val_accuracy: 0.6635 - lr: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testX, testY, batch_size=128, workers=1, use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyXC-IQkJ25i",
        "outputId": "dfa42aa1-8185-49b3-9f96-faed792cd880"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 23ms/step - loss: 1.7289 - accuracy: 0.6419\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7289478778839111, 0.6419000029563904]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loss\n",
        "plt.plot(r1.history['loss'], label='train loss')\n",
        "plt.plot(r1.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r1.history['accuracy'], label='train acc')\n",
        "plt.plot(r1.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model.save('./SQNet.h5')\n"
      ],
      "metadata": {
        "id": "mv6JvU8YvMMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "k_OcH4DUvMKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84853cc4-7221-48a4-d18c-a2b3973ce933"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 96)   14112       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 96)  384         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 96)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 8, 8, 16)     1536        ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 8, 8, 16)    64          ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 8, 8, 64)     1024        ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 8, 8, 64)     9216        ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 8, 8, 64)    256         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 8, 8, 64)    256         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 8, 8, 128)    0           ['batch_normalization_27[0][0]', \n",
            "                                                                  'batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 8, 8, 16)     2048        ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 8, 8, 16)    64          ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 8, 8, 64)     1024        ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 8, 8, 64)     9216        ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 8, 8, 64)    256         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 8, 8, 64)    256         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 8, 8, 128)    0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 8, 8, 32)     4096        ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 8, 8, 32)    128         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 8, 8, 128)    4096        ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 8, 8, 128)    36864       ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 8, 8, 128)   512         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 8, 8, 128)   512         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 8, 8, 256)    0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 256)   0           ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 4, 4, 32)     8192        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 4, 4, 32)    128         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 4, 4, 128)    4096        ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 4, 4, 128)    36864       ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 4, 4, 128)   512         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 4, 4, 128)   512         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 4, 4, 256)    0           ['batch_normalization_36[0][0]', \n",
            "                                                                  'batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 4, 4, 48)     12288       ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 4, 4, 48)    192         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 4, 4, 192)    9216        ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 4, 4, 192)    82944       ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 4, 4, 192)   768         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 4, 4, 192)   768         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 4, 4, 384)    0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 4, 4, 48)     18432       ['concatenate_12[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 4, 4, 48)    192         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 4, 4, 192)    9216        ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 4, 4, 192)    82944       ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 4, 4, 192)   768         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 4, 4, 192)   768         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 4, 4, 384)    0           ['batch_normalization_42[0][0]', \n",
            "                                                                  'batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 4, 4, 64)     24576       ['concatenate_13[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 4, 4, 64)    256         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 4, 4, 256)    16384       ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 4, 4, 256)    147456      ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 4, 4, 512)    0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 512)   0           ['concatenate_14[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 2, 2, 64)     32768       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 2, 2, 64)    256         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 2, 2, 256)    16384       ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 2, 2, 256)    147456      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 2, 2, 512)    0           ['batch_normalization_48[0][0]', \n",
            "                                                                  'batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 2, 2, 10)     5130        ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 10)          0           ['conv2d_51[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 10)           0           ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 749,482\n",
            "Trainable params: 743,530\n",
            "Non-trainable params: 5,952\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pl_UQg0hLEcC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQNetSE"
      ],
      "metadata": {
        "id": "FDyQhC-SNIjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout\n",
        "from keras.layers import Concatenate, Input, GlobalAveragePooling2D, Dense, Multiply\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "def SqueezeNetSE(input_shape, classes):\n",
        "\n",
        "\n",
        "  def SqueezeAndExcitation(inputs, ratio=8):\n",
        "    \n",
        "    b, h, w, c = inputs.shape\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(inputs)\n",
        "    x = Dense(c//ratio, activation='relu', use_bias=False)(x)\n",
        "    x = Dense(c, activation='sigmoid', use_bias=False)(x)\n",
        "    \n",
        "    x = Multiply()([inputs, x])\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "  def Fire(inputs, fs, fe):\n",
        "    \n",
        "    s1 = Conv2D(filters=fs, kernel_size=1, padding='same', use_bias=False, activation='relu')(inputs)\n",
        "    s1 = BatchNormalization()(s1)\n",
        "    e1 = Conv2D(filters=fe, kernel_size=1, padding='same', use_bias=False, activation='relu')(s1)\n",
        "    e1 = BatchNormalization()(e1)\n",
        "    e3 = Conv2D(filters=fe, kernel_size=3, padding='same', use_bias=False, activation='relu')(s1)\n",
        "    e3 = BatchNormalization()(e3)\n",
        "\n",
        "    output = Concatenate()([e1, e3])\n",
        "  \n",
        "    return output\n",
        "\n",
        "\n",
        "  inputs = Input(input_shape)\n",
        "  x1 = Conv2D(filters=96, kernel_size=7, strides=2, padding='same', use_bias=False, activation='relu')(inputs)\n",
        "  x1= s1 = BatchNormalization()(x1)\n",
        "  x1 = MaxPooling2D(pool_size=3, strides=2, padding='same')(x1)\n",
        "\n",
        "  f2 = Fire(x1, 16, 64)\n",
        "  f3 = Fire(f2, 16, 64)\n",
        "  f4 = Fire(f3, 32, 128)\n",
        "  f4 = SqueezeAndExcitation(f4, ratio=16)\n",
        "  x1 = MaxPooling2D(pool_size=3, strides=2, padding='same')(f4)\n",
        "\n",
        "  f5 = Fire(x1, 32, 128)\n",
        "  f6 = Fire(f5, 48, 192)\n",
        "  f7 = Fire(f6, 48, 192)\n",
        "  f8 = Fire(f7, 64, 256)\n",
        "  f8 = SqueezeAndExcitation(f8, ratio=16)\n",
        "\n",
        "  x1 = MaxPooling2D(pool_size=3, strides=2, padding='same')(f8)\n",
        "\n",
        "  f8 = Fire(x1, 64, 256)\n",
        "  x1 = Conv2D(filters=classes, kernel_size=1)(f8)\n",
        "  x1 = GlobalAveragePooling2D()(x1)\n",
        "\n",
        "  if classes == 1:\n",
        "    x1 = Activation('sigmoid')(x1)\n",
        "  else:\n",
        "    x1 = Activation('softmax')(x1)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=x1)\n",
        "  # model.summary()\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "0nv7p3UsuatO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\"\"\" callbacks \"\"\"\n",
        "checkpoint_filepath = '/content/SQNET_{epoch}.h5'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    # monitor='val_iou_score',\n",
        "    # mode='max',\n",
        "    verbose = 1,\n",
        "    period = 5,\n",
        "    save_best_only=False\n",
        "    )\n",
        "\n",
        "callbacks = [\n",
        "    model_checkpoint_callback,\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.5, verbose=1),\n",
        "    CSVLogger('/content/SQNET.csv'),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=8)\n",
        "]"
      ],
      "metadata": {
        "id": "s1wfkM1_uvyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5111d2b6-1a16-46c2-d1dd-e562ac70c59f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SqueezeNetSE(input_shape = (32, 32, 3), classes=10)\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "IuAr6mn5uvy9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = model.fit(\n",
        "    trainX, trainY,\n",
        "    validation_data=(valX, valY),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    steps_per_epoch=len(trainX)//128 + 1,\n",
        "    validation_steps=len(valX)//128 + 1,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "1xNjwMqCuvy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79226d09-4a5c-49ac-9e25-9a964e8d8443"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "333/333 [==============================] - 22s 56ms/step - loss: 1.7884 - accuracy: 0.3590 - val_loss: 2.8851 - val_accuracy: 0.3107 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 1.4225 - accuracy: 0.4867 - val_loss: 1.7953 - val_accuracy: 0.4325 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 1.2975 - accuracy: 0.5293 - val_loss: 2.0426 - val_accuracy: 0.3972 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 1.1796 - accuracy: 0.5759 - val_loss: 2.2541 - val_accuracy: 0.3885 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 1.0895 - accuracy: 0.6117\n",
            "Epoch 5: val_loss improved from inf to 1.85149, saving model to /content/SQNET_5.h5\n",
            "333/333 [==============================] - 19s 56ms/step - loss: 1.0897 - accuracy: 0.6117 - val_loss: 1.8515 - val_accuracy: 0.5016 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 1.0163 - accuracy: 0.6419 - val_loss: 2.0052 - val_accuracy: 0.4716 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.9518 - accuracy: 0.6657 - val_loss: 1.2905 - val_accuracy: 0.5944 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "333/333 [==============================] - 18s 55ms/step - loss: 0.8837 - accuracy: 0.6924 - val_loss: 1.2130 - val_accuracy: 0.6072 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "333/333 [==============================] - 18s 56ms/step - loss: 0.8553 - accuracy: 0.7023 - val_loss: 1.1138 - val_accuracy: 0.6387 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.8390 - accuracy: 0.7090\n",
            "Epoch 10: val_loss improved from 1.85149 to 1.07480, saving model to /content/SQNET_10.h5\n",
            "333/333 [==============================] - 19s 56ms/step - loss: 0.8391 - accuracy: 0.7090 - val_loss: 1.0748 - val_accuracy: 0.6453 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "333/333 [==============================] - 18s 55ms/step - loss: 0.7647 - accuracy: 0.7360 - val_loss: 1.2795 - val_accuracy: 0.6081 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "333/333 [==============================] - 18s 53ms/step - loss: 0.7380 - accuracy: 0.7428 - val_loss: 1.1036 - val_accuracy: 0.6393 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.7282 - accuracy: 0.7493 - val_loss: 1.4065 - val_accuracy: 0.5851 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.6585 - accuracy: 0.7722 - val_loss: 1.5202 - val_accuracy: 0.5867 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.7803\n",
            "Epoch 15: val_loss improved from 1.07480 to 1.06196, saving model to /content/SQNET_15.h5\n",
            "333/333 [==============================] - 18s 55ms/step - loss: 0.6316 - accuracy: 0.7803 - val_loss: 1.0620 - val_accuracy: 0.6565 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "333/333 [==============================] - 18s 53ms/step - loss: 0.6407 - accuracy: 0.7790 - val_loss: 1.7669 - val_accuracy: 0.5383 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "333/333 [==============================] - 18s 53ms/step - loss: 0.6071 - accuracy: 0.7900 - val_loss: 1.1760 - val_accuracy: 0.6569 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.5525 - accuracy: 0.8107 - val_loss: 1.1229 - val_accuracy: 0.6691 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.5474 - accuracy: 0.8100 - val_loss: 0.9524 - val_accuracy: 0.7036 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.8113\n",
            "Epoch 20: val_loss did not improve from 1.06196\n",
            "333/333 [==============================] - 18s 53ms/step - loss: 0.5441 - accuracy: 0.8113 - val_loss: 1.0973 - val_accuracy: 0.6740 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.5163 - accuracy: 0.8196 - val_loss: 0.8293 - val_accuracy: 0.7416 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.4663 - accuracy: 0.8376 - val_loss: 0.9444 - val_accuracy: 0.7091 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.4689 - accuracy: 0.8390 - val_loss: 1.1850 - val_accuracy: 0.6721 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.4404 - accuracy: 0.8461 - val_loss: 1.0669 - val_accuracy: 0.6923 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.4179 - accuracy: 0.8559\n",
            "Epoch 25: val_loss did not improve from 1.06196\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.4180 - accuracy: 0.8559 - val_loss: 1.2701 - val_accuracy: 0.6608 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "332/333 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.8454\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.4493 - accuracy: 0.8453 - val_loss: 0.9054 - val_accuracy: 0.7212 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.2770 - accuracy: 0.9041 - val_loss: 1.1146 - val_accuracy: 0.7040 - lr: 0.0050\n",
            "Epoch 28/100\n",
            "333/333 [==============================] - 18s 54ms/step - loss: 0.2309 - accuracy: 0.9195 - val_loss: 1.1295 - val_accuracy: 0.7305 - lr: 0.0050\n",
            "Epoch 29/100\n",
            "333/333 [==============================] - 18s 53ms/step - loss: 0.1859 - accuracy: 0.9362 - val_loss: 1.6934 - val_accuracy: 0.6423 - lr: 0.0050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testX, testY, batch_size=128, workers=1, use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cQ3O457LR3t",
        "outputId": "bd83805f-2c23-4235-f9fb-9c7051c5790b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 17ms/step - loss: 1.7823 - accuracy: 0.6277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.782346248626709, 0.6276999711990356]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loss\n",
        "plt.plot(r1.history['loss'], label='train loss')\n",
        "plt.plot(r1.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r1.history['accuracy'], label='train acc')\n",
        "plt.plot(r1.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model.save('./SQNetSE.h5')\n"
      ],
      "metadata": {
        "id": "FcqfSSzGuaof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "2b7265a9-8188-40a7-b93e-b9b5a7814a5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iimKeRGpLTLm",
        "outputId": "e7fc4b7d-e148-43ff-ef53-f53a7c618fbf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 16, 16, 96)   14112       ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 16, 16, 96)  384         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 96)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 8, 8, 16)     1536        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 8, 8, 16)    64          ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 8, 8, 64)     1024        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 8, 8, 64)     9216        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 8, 8, 64)    256         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 8, 8, 64)    256         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 8, 8, 128)    0           ['batch_normalization_52[0][0]', \n",
            "                                                                  'batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 8, 8, 16)     2048        ['concatenate_16[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 8, 8, 16)    64          ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 8, 8, 64)     1024        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 8, 8, 64)     9216        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 8, 8, 64)    256         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 8, 8, 64)    256         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenate)   (None, 8, 8, 128)    0           ['batch_normalization_55[0][0]', \n",
            "                                                                  'batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 8, 8, 32)     4096        ['concatenate_17[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 8, 8, 32)    128         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 8, 8, 128)    4096        ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 8, 8, 128)    36864       ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 8, 8, 128)   512         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 8, 8, 128)   512         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 8, 8, 256)    0           ['batch_normalization_58[0][0]', \n",
            "                                                                  'batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 256)         0           ['concatenate_18[0][0]']         \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           4096        ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          4096        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8, 8, 256)    0           ['concatenate_18[0][0]',         \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 256)   0           ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 4, 4, 32)     8192        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 4, 4, 32)    128         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 4, 4, 128)    4096        ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 4, 4, 128)    36864       ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 4, 4, 128)   512         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 4, 4, 128)   512         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 4, 4, 256)    0           ['batch_normalization_61[0][0]', \n",
            "                                                                  'batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 4, 4, 48)     12288       ['concatenate_19[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 4, 4, 48)    192         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 4, 4, 192)    9216        ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 4, 4, 192)    82944       ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 4, 4, 192)   768         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 4, 4, 192)   768         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 4, 4, 384)    0           ['batch_normalization_64[0][0]', \n",
            "                                                                  'batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 4, 4, 48)     18432       ['concatenate_20[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 4, 4, 48)    192         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 4, 4, 192)    9216        ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 4, 4, 192)    82944       ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 4, 4, 192)   768         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 4, 4, 192)   768         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 4, 4, 384)    0           ['batch_normalization_67[0][0]', \n",
            "                                                                  'batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 4, 4, 64)     24576       ['concatenate_21[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 4, 4, 64)    256         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 4, 4, 256)    16384       ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 4, 4, 256)    147456      ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 4, 4, 512)    0           ['batch_normalization_70[0][0]', \n",
            "                                                                  'batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3 (Gl  (None, 512)         0           ['concatenate_22[0][0]']         \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           16384       ['global_average_pooling2d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 512)          16384       ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 4, 4, 512)    0           ['concatenate_22[0][0]',         \n",
            "                                                                  'dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 2, 2, 512)   0           ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 2, 2, 64)     32768       ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 2, 2, 64)    256         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 2, 2, 256)    16384       ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 2, 2, 256)    147456      ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 2, 2, 512)    0           ['batch_normalization_73[0][0]', \n",
            "                                                                  'batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 2, 2, 10)     5130        ['concatenate_23[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4 (Gl  (None, 10)          0           ['conv2d_77[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 10)           0           ['global_average_pooling2d_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 790,442\n",
            "Trainable params: 784,490\n",
            "Non-trainable params: 5,952\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uBLOcJO6Ll4d"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2i9OtNd_M61A",
        "VXWvsn9zNAA9",
        "FDyQhC-SNIjL"
      ],
      "name": "SQNET_cifar10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}